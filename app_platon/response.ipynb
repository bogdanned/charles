{
cells: [
{
cell_type: "code",
execution_count: 1,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience) "
]
}
],
source: [
"# things we need for NLP ",
"import nltk ",
"from nltk.stem.lancaster import LancasterStemmer ",
"stemmer = LancasterStemmer() ",
" ",
"# things we need for Tensorflow ",
"import numpy as np ",
"import tflearn ",
"import tensorflow as tf ",
"import random"
]
},
{
cell_type: "code",
execution_count: 2,
metadata: {
collapsed: true
},
outputs: [ ],
source: [
"# restore all of our data structures ",
"import pickle ",
"data = pickle.load( open( "training_data", "rb" ) ) ",
"words = data['words'] ",
"classes = data['classes'] ",
"train_x = data['train_x'] ",
"train_y = data['train_y'] ",
" ",
"# import our chat-bot intents file ",
"import json ",
"with open('intents.json') as json_data: ",
" intents = json.load(json_data)"
]
},
{
cell_type: "code",
execution_count: 3,
metadata: {
collapsed: false,
scrolled: true
},
outputs: [ ],
source: [
"# Build neural network ",
"net = tflearn.input_data(shape=[None, len(train_x[0])]) ",
"net = tflearn.fully_connected(net, 8) ",
"net = tflearn.fully_connected(net, 8) ",
"net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax') ",
"net = tflearn.regression(net) ",
" ",
"# Define model and setup tensorboard ",
"model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
]
},
{
cell_type: "code",
execution_count: 4,
metadata: {
collapsed: true
},
outputs: [ ],
source: [
"def clean_up_sentence(sentence): ",
" # tokenize the pattern ",
" sentence_words = nltk.word_tokenize(sentence) ",
" # stem each word ",
" sentence_words = [stemmer.stem(word.lower()) for word in sentence_words] ",
" return sentence_words ",
" ",
"# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence ",
"def bow(sentence, words, show_details=False): ",
" # tokenize the pattern ",
" sentence_words = clean_up_sentence(sentence) ",
" # bag of words ",
" bag = [0]*len(words) ",
" for s in sentence_words: ",
" for i,w in enumerate(words): ",
" if w == s: ",
" bag[i] = 1 ",
" if show_details: ",
" print ("found in bag: %s" % w) ",
" ",
" return(np.array(bag))"
]
},
{
cell_type: "code",
execution_count: 5,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 ",
" 0 0 0 1 0 0 0 0 0 1 0] ",
"['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today'] "
]
}
],
source: [
"p = bow("is your shop open today?", words) ",
"print (p) ",
"print (classes)"
]
},
{
cell_type: "code",
execution_count: 6,
metadata: {
collapsed: false
},
outputs: [ ],
source: [
"# load our saved model ",
"model.load('./model.tflearn')"
]
},
{
cell_type: "code",
execution_count: 7,
metadata: {
collapsed: false
},
outputs: [ ],
source: [
"# create a data structure to hold user context ",
"context = {} ",
" ",
"ERROR_THRESHOLD = 0.25 ",
"def classify(sentence): ",
" # generate probabilities from the model ",
" results = model.predict([bow(sentence, words)])[0] ",
" # filter out predictions below a threshold ",
" results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD] ",
" # sort by strength of probability ",
" results.sort(key=lambda x: x[1], reverse=True) ",
" return_list = [] ",
" for r in results: ",
" return_list.append((classes[r[0]], r[1])) ",
" # return tuple of intent and probability ",
" return return_list ",
" ",
"def response(sentence, userID='123', show_details=False): ",
" results = classify(sentence) ",
" # if we have a classification then find the matching intent tag ",
" if results: ",
" # loop as long as there are matches to process ",
" while results: ",
" for i in intents['intents']: ",
" # find a tag matching the first result ",
" if i['tag'] == results[0][0]: ",
" # set context for this intent if necessary ",
" if 'context_set' in i: ",
" if show_details: print ('context:', i['context_set']) ",
" context[userID] = i['context_set'] ",
" ",
" # check if this intent is contextual and applies to this user's conversation ",
" if not 'context_filter' in i or \ ",
" (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]): ",
" if show_details: print ('tag:', i['tag']) ",
" # a random response from the intent ",
" return print(random.choice(i['responses'])) ",
" ",
" results.pop(0)"
]
},
{
cell_type: "code",
execution_count: 8,
metadata: {
collapsed: false
},
outputs: [
{
data: {
text/plain: [
"[('opentoday', 0.7987914085388184)]"
]
},
execution_count: 8,
metadata: { },
output_type: "execute_result"
}
],
source: [
"classify('is your shop open today?')"
]
},
{
cell_type: "code",
execution_count: 9,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"Our hours are 9am-9pm every day "
]
}
],
source: [
"response('is your shop open today?')"
]
},
{
cell_type: "code",
execution_count: 10,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"We accept most major credit cards "
]
}
],
source: [
"response('do you take cash?')"
]
},
{
cell_type: "code",
execution_count: 11,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"We rent Yamaha, Piaggio and Vespa mopeds "
]
}
],
source: [
"response('what kind of mopeds do you rent?')"
]
},
{
cell_type: "code",
execution_count: 12,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"Have a nice day "
]
}
],
source: [
"response('Goodbye, see you later')"
]
},
{
cell_type: "code",
execution_count: 13,
metadata: {
collapsed: false
},
outputs: [
{
data: {
text/plain: [
"{}"
]
},
execution_count: 13,
metadata: { },
output_type: "execute_result"
}
],
source: [
"context"
]
},
{
cell_type: "code",
execution_count: 14,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"Are you looking to rent today or later this week? "
]
}
],
source: [
"response('we want to rent a moped')"
]
},
{
cell_type: "code",
execution_count: 15,
metadata: {
collapsed: false
},
outputs: [
{
data: {
text/plain: [
"{'123': 'rentalday'}"
]
},
execution_count: 15,
metadata: { },
output_type: "execute_result"
}
],
source: [
"# show context ",
"context"
]
},
{
cell_type: "code",
execution_count: 16,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"We accept most major credit cards "
]
}
],
source: [
"response('today')"
]
},
{
cell_type: "code",
execution_count: 17,
metadata: {
collapsed: false
},
outputs: [
{
data: {
text/plain: [
"[('payments', 0.32852643728256226), ('today', 0.3266606032848358)]"
]
},
execution_count: 17,
metadata: { },
output_type: "execute_result"
}
],
source: [
"classify('today')"
]
},
{
cell_type: "code",
execution_count: 18,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"context: ",
"tag: greeting ",
"Hello, thanks for visiting "
]
}
],
source: [
"# clear context ",
"response("Hi there!", show_details=True)"
]
},
{
cell_type: "code",
execution_count: 19,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"We accept VISA, Mastercard and AMEX "
]
},
{
data: {
text/plain: [
"[('payments', 0.32852643728256226), ('today', 0.3266606032848358)]"
]
},
execution_count: 19,
metadata: { },
output_type: "execute_result"
}
],
source: [
"response('today') ",
"classify('today')"
]
},
{
cell_type: "code",
execution_count: 20,
metadata: {
collapsed: false
},
outputs: [
{
name: "stdout",
output_type: "stream",
text: [
"Happy to help! "
]
}
],
source: [
"response("thanks, your great")"
]
}
],
metadata: {
kernelspec: {
display_name: "Python 3",
language: "python",
name: "python3"
},
language_info: {
codemirror_mode: {
name: "ipython",
version: 3
},
file_extension: ".py",
mimetype: "text/x-python",
name: "python",
nbconvert_exporter: "python",
pygments_lexer: "ipython3",
version: "3.5.2"
}
},
nbformat: 4,
nbformat_minor: 1
}
